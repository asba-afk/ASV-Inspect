# ğŸ” ASV-INSPECT - Automated Assembly Verification System

An AI-powered computer vision system for automated inspection of mechanical assemblies using YOLOv8 object detection.

## ğŸ“‹ Overview

ASV-INSPECT is a complete assembly inspection solution that detects missing components in mechanical assemblies. It uses deep learning (YOLOv8) to identify components and compares them against a golden model to verify assembly completeness.

### Key Features

- âœ… **Real-time Component Detection** - YOLOv8 nano model (94% mAP50)
- ğŸ¯ **Multiple Detection Modes** - Position-based or count-based verification
- ğŸ–¥ï¸ **Interactive Web Interface** - Streamlit-based UI for easy operation
- ğŸ“Š **Detailed Reporting** - Visual annotations and JSON reports
- âš™ï¸ **Adjustable Parameters** - Confidence threshold and position tolerance controls
- ğŸ”„ **Batch Processing** - Inspect multiple assemblies efficiently

### Detected Components

- **Bolts** (12 expected per assembly)
- **Bearings** (4 expected per assembly)
- **Oil Jets** (2 expected per assembly)

**Total Expected: 18 components per assembly**

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- Windows/Linux/macOS
- 4GB RAM minimum (8GB recommended)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/ASV-Inspect.git
   cd ASV-Inspect
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   # Windows
   venv\Scripts\activate
   # Linux/Mac
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

### Running the Application

**Option 1: Web Interface (Recommended)**
```bash
streamlit run app.py
```
Then open http://localhost:8501 in your browser.

**Option 2: Command Line**
```bash
python src/inspect_assembly.py --image path/to/image.jpg
```

## ğŸ“– Usage

### Web Interface

1. **Upload Image** - Drag and drop or browse for assembly image
2. **Adjust Settings** (optional):
   - **Confidence Threshold** (0.01-1.0): Lower = detect more components
   - **Position Tolerance** (0.05-0.80): Higher = accept components further from expected positions
   - **Count Only Mode**: Enable to ignore positions (recommended for varying camera angles)

3. **View Results**:
   - Green boxes: Detected components
   - Red circles: Missing component locations (position-based mode)
   - Status banner: PASS/FAIL with compliance percentage

4. **Take Action**:
   - âœ“ Mark as Verified
   - ğŸ”„ Check Another Image

### Detection Modes

**Position-Based Mode** (Default disabled)
- Matches detections to expected component positions
- Shows WHERE missing components should be
- âš ï¸ Requires consistent camera positioning (same angle/distance as training images)

**Count-Only Mode** (Default enabled)
- Simply counts components by type
- Works with any camera angle/position
- Can't show specific missing component locations
- âœ… Recommended for production use with varying camera setups

## ğŸ“ Project Structure

```
ASV-Inspect/
â”œâ”€â”€ app.py                      # Streamlit web interface
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ inspect_assembly.py     # Core inspection logic
â”‚   â”œâ”€â”€ train_detector.py       # YOLO model training
â”‚   â”œâ”€â”€ build_golden_model.py   # Golden model creation
â”‚   â”œâ”€â”€ visualize.py            # Result visualization
â”‚   â”œâ”€â”€ utils.py                # Utility functions
â”‚   â””â”€â”€ data_loader.py          # Data loading utilities
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ detector/               # Trained YOLO model
â”‚   â””â”€â”€ golden_model/           # Reference component positions
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ images/                 # Training images
â”‚   â”œâ”€â”€ labels/                 # YOLO annotations
â”‚   â””â”€â”€ data.yaml               # Dataset configuration
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ images/                 # Annotated result images
â”‚   â””â”€â”€ reports/                # JSON inspection reports
â”œâ”€â”€ docs/                       # Documentation
â”œâ”€â”€ example_batch.py            # Batch processing example
â””â”€â”€ example_inference.py        # Single image example
```

## ğŸ“ Training Your Own Model

### 1. Prepare Dataset

Place images in `dataset/images/` and YOLO labels in `dataset/labels/`

Format: `class_id x_center y_center width height`

### 2. Train Detector

```bash
python src/train_detector.py --epochs 100 --batch 16 --device cpu
```

For GPU training:
```bash
python src/train_detector.py --epochs 100 --batch 16 --device 0
```

### 3. Build Golden Model

```bash
python src/build_golden_model.py
```

Uses k-means clustering to determine expected component positions and counts.

## ğŸ“Š Model Performance

- **Model**: YOLOv8 nano
- **Parameters**: 3,011,433
- **Overall mAP50**: 94.0%
- **Per-Class Performance**:
  - Bolt: 99.4% mAP50
  - Bearing: 99.5% mAP50
  - Oil Jet: 83.1% mAP50

Training Details:
- 100 epochs
- 139 training images
- 2,454 total detections
- CPU training time: ~11.3 hours

## ğŸ”§ Configuration

### Key Parameters

- `confidence_threshold`: Minimum detection confidence (default: 0.05)
- `base_tolerance`: Position matching tolerance (default: 0.50)
- `use_adaptive_tolerance`: Adjust tolerance based on component variance

### Adjusting for Your Use Case

**High False Positives** (detects non-existent components):
- Increase confidence threshold (0.15-0.30)

**Missing Visible Components**:
- Lower confidence threshold (0.01-0.05)
- Check lighting and image quality

**Position Matching Issues**:
- Increase position tolerance (0.50-0.70)
- Or enable Count Only Mode

## ğŸ› Troubleshooting

### Red circles in wrong locations
**Cause**: Assembly positioned differently than training images  
**Solution**: Enable "Count Only Mode" or ensure consistent camera positioning

### Not detecting all visible components
**Cause**: Confidence threshold too high  
**Solution**: Lower confidence threshold slider to 0.01-0.05

### False missing components on complete assemblies
**Cause**: Position tolerance too strict  
**Solution**: Increase position tolerance or use Count Only Mode

## ğŸ“š Documentation

Detailed documentation available in `/docs`:
- [Architecture Guide](docs/ARCHITECTURE.md)
- [Configuration Guide](docs/CONFIGURATION.md)
- [Quick Start Guide](docs/QUICKSTART_GUIDE.md)
- [Workflow Documentation](docs/WORKFLOW.md)

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit issues and pull requests.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- YOLOv8 by Ultralytics
- Streamlit for the web framework
- OpenCV for image processing

## ğŸ“ Support

For questions or issues, please open an issue on GitHub.

---

**Made with â¤ï¸ for automated quality inspection**
